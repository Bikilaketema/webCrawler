# Information Retrieval System with Web Crawler

This repository contains two directories: `crawler` and `isr-system-with-ui`, each serving a specific purpose in the implementation of an Information Retrieval (IR) System.

## Crawler

The `crawler` directory contains a Python Scrapy-based web crawler. This crawler is designed to fetch data from web pages, facilitating the collection of data for the IR system. It can be configured to crawl specific websites or domains, extract relevant information, and store it for indexing and retrieval.

### Usage

To use the crawler:
1. Navigate to the `crawler` directory.
2. Install the required dependencies using `pip install -r requirements.txt`.
3. Configure the crawler settings and rules as needed.
4. Run the crawler using the appropriate Scrapy command.

## ISR System with UI

The `isr-system-with-ui` directory contains the implementation of an Information Retrieval System (IRS) with a user interface (UI). Built using React, this system preprocesses data, indexes it, measures similarity, ranks results, and provides an interactive interface for querying the system.

### Usage

To use the ISR system with UI:
1. Navigate to the `isr-system-with-ui` directory.
2. Install the required dependencies for both the frontend and backend using `npm install`.
3. Configure the system settings, including Elasticsearch connection details.
4. Start the system using the appropriate commands (`npm start`).
5. Access the system via the provided URL and interact with the UI to query and retrieve information.

## Contributors

- [Bikila Ketema](https://github.com/bikilaketema)

For detailed usage instructions and contribution guidelines, refer to the respective directories' README files.

For any queries or assistance, please contact [bikilaketema94@gmail.com](mailto:bikilaketema94@gmail.com).
